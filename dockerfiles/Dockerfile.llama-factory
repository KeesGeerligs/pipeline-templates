FROM pytorch/pytorch:2.7.1-cuda12.8-cudnn9-runtime

# ---------------------------------------------------------------------------
# 1. Extra compatibility layer so the container starts even on slightly older
#    drivers (down to 525) that some Nosana nodes may still run.
# ---------------------------------------------------------------------------
RUN apt-get update && \
    apt-get install -y --no-install-recommends cuda-compat-12-8 git && \
    rm -rf /var/lib/apt/lists/*

# ---------------------------------------------------------------------------
# 2. Common Python utilities your derived templates might expect.
#    (Add or remove as needed.)
# ---------------------------------------------------------------------------
RUN pip install --no-cache-dir --upgrade pip

# ---------------------------------------------------------------------------
# 3. Install LLaMA Factory
# ---------------------------------------------------------------------------
RUN git clone https://github.com/hiyouga/LLaMA-Factory.git /opt/llama-factory
WORKDIR /opt/llama-factory
RUN pip install --no-cache-dir -e .

# ---------------------------------------------------------------------------
# 4. Default workspace + command
# ---------------------------------------------------------------------------
EXPOSE 7860
CMD ["llamafactory-cli", "webui"]