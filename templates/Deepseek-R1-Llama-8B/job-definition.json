{
  "version": "0.1",
  "type": "container",
  "ops": [
    {
      "type": "container/run",
      "id": "Llama8b",
      "args": {
        "entrypoint": ["/bin/sh"],
        "cmd": [
          "-c",
          "python3 -m vllm.entrypoints.openai.api_server --model deepseek-ai/$MODEL --served-model-name $MODEL --port 9000"
        ],
        "env": {
          "MODEL": "DeepSeek-R1-Distill-Llama-8B"
        },
        "gpu": true,
        "image": "docker.io/vllm/vllm-openai:v0.7.2",
        "expose": [
          {
            "port": 9000,
            "health_checks": [
              {
                "body": "{\"model\":\"DeepSeek-R1-Distill-Llama-8B\",\"messages\":[{\"role\":\"user\",\"content\":\"Respond with a single word: Ready\"}],\"stream\":false}",
                "path": "/v1/chat/completions",
                "type": "http",
                "method": "POST",
                "headers": {
                  "Content-Type": "application/json"
                },
                "expected_status": 200,
                "continuous": true
              }
            ]
          }
        ]
      }
    }
  ],
  "meta": {
    "trigger": "dashboard",
    "system_requirements": {
      "required_vram": 16
    }
  }
}
