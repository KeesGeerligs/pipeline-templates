{
  "version": "0.1",
  "type": "container",
  "meta": {
    "trigger": "dashboard",
    "system_requirements": {
      "required_vram": 18
    }
  },
  "ops": [
    {
      "type": "container/run",
      "id": "ollama-service",
      "args": {
        "image": "docker.io/ollama/ollama:0.6.6",
        "entrypoint": [
          "/bin/sh"
        ],
        "cmd": [
          "-c",
          "ollama serve & sleep 5 && ollama pull $MODEL && tail -f /dev/null"
        ],
        "env": {
          "MODEL": "gemma3:27b-it-qat"
        },
        "gpu": true,
        "expose": 11434
      }
    }
  ]
} 