{
  "version": "0.1",
  "type": "container",
  "ops": [
    {
      "type": "container/run",
      "id": "Gemma3-4b",
      "args": {
        "image": "docker.io/ollama/ollama:0.12.0",
        "entrypoint": [
          "/bin/sh"
        ],
        "cmd": [
          "-c",
          "ollama serve & sleep 5 && ollama pull $MODEL && tail -f /dev/null"
        ],
        "env": {
          "MODEL": "gemma3:4b",
          "OLLAMA_ORIGINS": "*",
          "OLLAMA_HOST": "0.0.0.0:11434"
        },
        "gpu": true,
        "expose": [
          {
            "port": 11434,
            "health_checks": [
              {
                "body": "{\"model\":\"gemma3:4b-it-qat\",\"messages\":[{\"role\":\"user\",\"content\":\"Respond with a single word: Ready\"}],\"stream\":false}",
                "path": "/api/chat",
                "type": "http",
                "method": "POST",
                "headers": {
                  "Content-Type": "application/json"
                },
                "expected_status": 200,
                "continuous": false
              }
            ]
          }
        ]
      }
    }
  ],
  "meta": {
    "trigger": "dashboard",
    "system_requirements": {
      "required_vram": 4
    }
  }
}
